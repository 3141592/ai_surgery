# Transformers

## 01-27-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?


### What do I think I understand a little better now (or still don’t)?

My working mental model is that the data does exist inside transformer models to be able to
probe them to understand better how they work.

## 02-15-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?


### What do I think I understand a little better now (or still don’t)?

My working mental model is that the data does exist inside transformer models to be able to
probe them to understand better how they work.

## 02-20-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?

- Updated pretrained script to use fastText instead of GloVe.
- Review Ch 11.3.3

### What do I think I understand a little better now (or still don’t)?

- That newer pretrained embeddings work faster and better.


## 02-23-2026

### What question pulled me here?

- I contuned a review of how the Transformer encoder example from DLwP.

### What did I actually do?

- Updated dataset splitting to prevent leakage.

### What do I think I understand a little better now (or still don’t)?

- I still do not completely understand the Transformer encoder architecture.


## 02-26-2026

### What question pulled me here?

- I contuned a review of how the Transformer encoder example from DLwP.

### What did I actually do?

- Start to understand the TransformerEncoder model from DLWP, with print statements mostly recommended by ChatGPT.

### What do I think I understand a little better now (or still don’t)?

- I feel like I do not understand much, in spite of a significant investment of time.
- I will be taking a new approach, guided by ChatGPT, but with me doing all of the implementation.





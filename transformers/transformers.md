# Transformers

## 01-27-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?


### What do I think I understand a little better now (or still don’t)?

My working mental model is that the data does exist inside transformer models to be able to
probe them to understand better how they work.

## 02-15-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?


### What do I think I understand a little better now (or still don’t)?

My working mental model is that the data does exist inside transformer models to be able to
probe them to understand better how they work.

## 02-20-2026

### What question pulled me here?

- I need a review of how the Transformer architecture works.
- The best hands-on overview seems to be from Chapter 11 of Deep Learning with Python

### What did I actually do?

- Updated pretrained script to use fastText instead of GloVe.
- Review Ch 11.3.3

### What do I think I understand a little better now (or still don’t)?

- That newer pretrained embeddings work faster and better.
